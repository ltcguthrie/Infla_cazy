install.packages("readr")
install.packages("dplyr")
install.packages("extrafont")
install.packages("scales")
install.packages("scales")
install.packages("grid")
install.packages("RcolorBrewer")
install.packages("RColorBrewer")
install.packages("digest")
install.packages("stringr")
library(bigrquery)
install.packages("bigquery")
install.packages("bigrquery")
install.packages("ggplot2")
?grid.layout
??grid.layout
library(readr)
library(dplyr)
library(ggplot2)
library(extrafont)
library(scales)
library(RColorBrewer)
library(digest)
library(stringr)
fontFamily <- "Source Sans Pro"
fontTitle <- "Source Sans Pro Semibold"
color_palette = c("#16a085","#27ae60","#2980b9","#8e44ad","#f39c12","#c0392b","#1abc9c", "#2ecc71", "#3498db", "#9b59b6", "#f1c40f","#e74c3c")
neutral_colors = function(number) {
return (brewer.pal(11, "RdYlBu")[-c(5:7)][(number %% 8) + 1])
}
set1_colors = function(number) {
return (brewer.pal(9, "Set1")[c(-6,-8)][(number %% 7) + 1])
}
theme_custom <- function() {theme_bw(base_size = 8) +
theme(panel.background = element_rect(fill="#eaeaea"),
plot.background = element_rect(fill="white"),
panel.grid.minor = element_blank(),
panel.grid.major = element_line(color="#dddddd"),
axis.ticks.x = element_blank(),
axis.ticks.y = element_blank(),
axis.title.x = element_text(family=fontTitle, size=8, vjust=-.3),
axis.title.y = element_text(family=fontTitle, size=8, vjust=1.5),
panel.border = element_rect(color="#cccccc"),
text = element_text(color = "#1a1a1a", family=fontFamily),
plot.margin = unit(c(0.25,0.1,0.30,0.35), "cm"),
plot.title = element_text(family=fontTitle, size=9, vjust=1))
}
create_watermark <- function(source = '', filename = '', dark=F) {
symbols <- c('','', '', '')
symbol <- symbols[strtoi(substr(digest(filename),1,6), base=36) %% length(symbols)]
if (length(symbol)==0) symbol <- symbols[1]
bg_white = "#F0F0F0"
bg_text = '#969696'
if (dark) {
bg_white = "#000000"
bg_text = '#666666'
}
watermark <- ggplot(aes(x,y), data=data.frame(x=c(0.5), y=c(0.5))) + geom_point(color = "transparent") +
geom_text(x=0, y=0.9, label="By Max Woolf â€” minimaxir.com", family="Source Sans Pro", color=bg_text, size=1.75, hjust=0) +
geom_text(x=5, y=0.9, label="Made using R and ggplot2", family="Source Sans Pro", color=bg_text, size=1.75) +
#geom_text(x=0, y=1.01, label = symbol, family = 'FontAwesome', color=bg_text, size=2) +
#geom_text(x=8, y=1, label = "via FiveThirtyEight", family="M+ 1m light", color="white") +
scale_x_continuous(limits=c(0,10)) +
scale_y_continuous(limits=c(0.5,1.5)) +
annotate("segment", x = 0, xend = 10, y=1.5, yend=1.5, color=bg_text, size=0.1) +
theme_bw() +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = "none",
panel.border = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(),
axis.ticks = element_blank(), plot.margin = unit(c(0.1,0,-0.4,0), "cm")) +
theme(plot.background=element_rect(fill=bg_white, color=bg_white),panel.background=element_rect(fill=bg_white, color=bg_white)) +
scale_color_manual(values=bg_text)
if (nchar(source) > 0) {watermark <- watermark + geom_text(x=10, y=0.9, label=paste("Data via",source), family="Source Sans Pro", color=bg_text, size=1.75, hjust=1)}
return (watermark)
}
web_Layout <- grid.layout(nrow = 2, ncol = 1, heights = unit(c(2,
0.125), c("null", "null")), )
library(grid)
web_Layout <- grid.layout(nrow = 2, ncol = 1, heights = unit(c(2,
0.125), c("null", "null")), )
library(httr)
install.packages("httpuv")
library(biqrquery)
library(bigrquery)
library(bigrquery)
library(methods) # needed for query_exec in Jupyter: https://github.com/hadley/bigrquery/issues/32
options(repr.plot.mimetypes = 'image/png', repr.plot.width=4, repr.plot.height=3, repr.plot.res=300)
sessionInfo()
project_id <- "nyctaxi"   # DO NOT SHARE!
query <- "SELECT ROUND(pickup_latitude, 4) AS lat,
ROUND(pickup_longitude, 4) AS long,
COUNT(*) AS num_pickups,
SUM(fare_amount) AS total_revenue
FROM [nyc-tlc:yellow.trips]
WHERE fare_amount/trip_distance BETWEEN 2 AND 10
GROUP BY lat, long"
df <- tbl_df(query_exec(query, project=project_id, max_pages=Inf))
library('ggthemes')
install.packages("ggthemes")
install.packages(reshape)
install.packages("reshape")
?https://2.bp.blogspot.com/-SpjgitfNMb0/TteevRR_Y2I/AAAAAAAAAFQ/IZgd32z2AI8/s1600/distributions.png
?fitdistr()
library(MASS)
?fitdistr()
install.packages("gridExtra")
library(gridExtra)
install.packages(ggmap)
install.packages("ggmap")
install.packages("mmnet")
install.packages("DecisionCurve")
install.packages("BioPET")
library(DecisionCurve)
library(rms)
data(dcaData)
install.packages("rms")
library(rms)
head(dcaData)
#FITTING RISK MODELS USING LOGISTIC REGRESSION, ASSESSING CALIBRATION, OPTIMISM-CORRECTED PERFORMANCE
# use logistic regression to estimate risk function that uses Age, Sex, and two Markers
f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData)
print(f)
# C is apparent AUC
# Dxy is Somner's D=2(AUC-0.5)
#prevalance of cancer in the dataset is about 12%
mean(dcaData$Cancer)
#Assess Mean Calibration
#first, get predicted risks for individuals in the dataset
fitted.risks<-predict(f,dcaData,type="fitted")
mean(fitted.risks)
#Assess Logistic Calibration
#model fit must return the expanded design matrix
f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData, x=TRUE, y=TRUE)
#set the seed for bootstrapping
set.seed(1796)
validate(f, B=400)
#look at the index.corrected column for optimism-corrected estimates
#logistic interept is 0 apparent but optimism-corrected is -0.0438
#logistic slope is 1 apparent but optimism-corrected is 0.9507 - indicating that high risks are over estimated and low risks are underestimated
#Assess Moderate Calibration
#Calibration curve
#use function with the RMS package
#m tells average number of people in each group; dataset has 500 people, so m=50 for deciles
val.prob(predict(f,dcaData,type="fitted"),dcaData[,6], m=50, statloc=FALSE)
#use modified function from Steyerberg grup that includes: confidence intervals and gives histogram of predicted risks separatley for cases and controls
source("P:\\Talks\\2016\\SISCR\\tutorial\\val.prob.ci.June09.r")
/Users/leahguthrie/Downloads/Module_7/SISCR2016_Module7_Rcode
source("/Users/leahguthrie/Downloads/Module_7/SISCR2016_Module7_Rcode/val.prob.ci.June09.r")
val.prob.ci(predict(f,dcaData,type="fitted"),dcaData[,6], m=50)
#to remove the statistics printed in the graph: set statloc=FALSE
##  INCREMENTAL VALUE
#Let's suppose that Marker 1 is and established biomarker and Marker 2 is a potentially useful new biomarker
set.seed(9876)
#DecisionCurve calculations for predicting cancer using age, sex, and smoking status
#set bootstraps = 50 here to reduce computation time.
baseline.model <- decision_curve(Cancer~Age + Female + Smokes + Marker1, #fitting a logistic model
data = dcaData,
study.design = "cohort",
bootstraps = 50)
#plot the Decision curve for baseline model
plot_decision_curve(baseline.model,  curve.names = "baseline model")
plot_decision_curve(baseline.model,  curve.names = "baseline model", xlim=c(0, .55))
plot_decision_curve(baseline.model, standardize=F, curve.names = "baseline model", xlim=c(0, 0.55))
full.model <- decision_curve(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData, bootstraps = 50)
#since we want to plot more than one curve, we pass a list of 'DecisionCurve' objects to the plot
plot_decision_curve( list(baseline.model, full.model),  curve.names = c("Baseline model", "Full model"), xlim=c(0, .55))
#we can also get a table summarizing results
summary(full.model)
#Plot ROC alternative for full model that includes biomarkers
plot_roc_components(full.model,  xlim = c(0, 0.4),col = c("black", "red"))
library(DecisionCurve)
library(rms)
#load (simulated) data for risk of  cancer
data(dcaData)
head(dcaData)
#FITTING RISK MODELS USING LOGISTIC REGRESSION, ASSESSING CALIBRATION, OPTIMISM-CORRECTED PERFORMANCE
f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData)
print(f)
# C is apparent AUC
# Dxy is Somner's D=2(AUC-0.5)
#prevalance of cancer in the dataset is about 12%
mean(dcaData$Cancer)
#Assess Mean Calibration
#first, get predicted risks for individuals in the dataset
fitted.risks<-predict(f,dcaData,type="fitted")
mean(fitted.risks)
#Assess Logistic Calibration
#model fit must return the expanded design matrix
f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData, x=TRUE, y=TRUE)
#set the seed for bootstrapping
set.seed(1796)
validate(f, B=400)
#look at the index.corrected column for optimism-corrected estimates
#logistic interept is 0 apparent but optimism-corrected is -0.0438
#logistic slope is 1 apparent but optimism-corrected is 0.9507 - indicating that high risks are over estimated and low risks are underestimated
#Assess Moderate Calibration
#Calibration curve
#use function with the RMS package
val.prob(predict(f,dcaData,type="fitted"),dcaData[,6], m=50, statloc=FALSE)
val.prob(predict(f,dcaData,type="fitted"),dcaData[,6], m=50, statloc=FALSE)
val.prob(predict(f,dcaData,type="fitted"),dcaData[,6], m=50, statloc=FALSE)
#use modified function from Steyerberg grup that includes: confidence intervals and gives histogram of predicted risks separatley for cases and controls
source("/Users/leahguthrie/Downloads/Module_7/SISCR2016_Module7_Rcode/val.prob.ci.June09.r")
val.prob.ci(predict(f,dcaData,type="fitted"),dcaData[,6], m=50)
#to remove the statistics printed in the graph: set statloc=FALSE
##  INCREMENTAL VALUE
#Let's suppose that Marker 1 is and established biomarker and Marker 2 is a potentially useful new biomarker
set.seed(9876)
#DecisionCurve calculations for predicting cancer using age, sex, and smoking status
#set bootstraps = 50 here to reduce computation time.
baseline.model <- decision_curve(Cancer~Age + Female + Smokes + Marker1, #fitting a logistic model
data = dcaData,
study.design = "cohort",
bootstraps = 50)
#plot the Decision curve for baseline model
plot_decision_curve(baseline.model,  curve.names = "baseline model")
plot_decision_curve(baseline.model,  curve.names = "baseline model", xlim=c(0, .55))
#switch to Net Benefit rather than standardized Net Benefit
plot_decision_curve(baseline.model, standardize=F, curve.names = "baseline model", xlim=c(0, 0.55))
#Examine the potential for the new biomarkers to improve Net Benefit
full.model <- decision_curve(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData, bootstraps = 50)
#since we want to plot more than one curve, we pass a list of 'DecisionCurve' objects to the plot
plot_decision_curve( list(baseline.model, full.model),  curve.names = c("Baseline model", "Full model"), xlim=c(0, .55))
#we can also get a table summarizing results
summary(full.model)
#Plot ROC alternative for full model that includes biomarkers
plot_roc_components(full.model,  xlim = c(0, 0.4),col = c("black", "red"))
#Clinical Impact Plot for full model that includes biomarkers
plot_clinical_impact(full.model, xlim = c(0, .4), col = c("black", "blue"))
library(BioPET)
library(BioPET)
library(BioPET)
library(pROC)
library(ggplot2)
library(gridExtra)
enrichment.baseline.model<-enrichment_analysis(formula=Cancer~Age+Smokes+Marker1, data=dcaData, cost.screening=50, cost.keeping=1000, reduction.under.treatment=0.7)
plot_enrichment_summaries(enrichment.baseline.model)
enrichment.full.model<-enrichment_analysis(formula=Cancer~Age+Smokes+Marker1+Marker2, data=dcaData, cost.screening=50, cost.keeping=1000, reduction.under.treatment=0.7)
plot_enrichment_summaries(enrichment.full.model)
head(dcaData)
tail(dcaData)
df = read.csv("/Users/leahguthrie/Einstein/Kelly-Lab/Labnotebook/Projects/CRC/data/CRCdata_11032016.csv")
head(df)
f<-lrm(Cancer~Age + BMI +  Red.meat. + Marker1L + Marker2R, data = df)
print(f)
f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData)
print(f)
f<-lrm(Cancer~Age + BMI +  Red.meat. + Marker1L + Marker2R, data = df)
print(f)
# C is apparent AUC
# Dxy is Somner's D=2(AUC-0.5)
mean(df$Cancer)
fitted.risks<-predict(f,df,type="fitted")
mean(fitted.risks)
#Assess Logistic Calibration
f<-lrm(Cancer~Age + BMI +  Red.meat. + Marker1L + Marker2R, data = df, x=TRUE, y=TRUE)
#f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData, x=TRUE, y=TRUE)
#set the seed for bootstrapping
set.seed(1796)
validate(f, B=400)
#look at the index.corrected column for optimism-corrected estimates
#logistic interept is 0 apparent but optimism-corrected is -0.0438
#logistic slope is 1 apparent but optimism-corrected is 0.9507 - indicating that high risks are over estimated and low risks are underestimated
#Assess Moderate Calibration
#Calibration curve
#use function with the RMS package
head(dcaData)
head(df)
val.prob(predict(f,df,type="fitted"),df[,7], m=3, statloc=FALSE)
source("/Users/leahguthrie/Downloads/Module_7/SISCR2016_Module7_Rcode/val.prob.ci.June09.r")
val.prob.ci(predict(f,df,type="fitted"),dcaData[,7], m=3)
val.prob.ci(predict(f,df,type="fitted"),df[,7], m=3)
set.seed(9876)
#DecisionCurve calculations for predicting cancer using age, sex, and smoking status
df = read.csv("/Users/leahguthrie/Einstein/Kelly-Lab/Labnotebook/Projects/CRC/data/CRC_clinicaldataF.csv")
df = read.csv("/Users/leahguthrie/Einstein/Kelly-Lab/Labnotebook/Projects/CRC/data/CRC_clinicaldataF.csv")
head(df)
f<-lrm(Cancer~GGT + BMI +  Vegetables + Red.meat. + Fiber + GOT + GPT+ Fruits, data = df)
f<-lrm(Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df)
print(f)
f<-lrm(Cancer~ Vegetables + Red.meat + Fiber + GOT + Fruits, data = df)
print(f)
f<-lrm(Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df)
print(f)
#prevalance of cancer in the dataset is about 45%
mean(df$Cancer)
fitted.risks<-predict(f,df,type="fitted")
mean(fitted.risks)
f<-lrm(Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df, x=TRUE, y=TRUE)
#f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData, x=TRUE, y=TRUE)
#set the seed for bootstrapping
set.seed(1796)
validate(f, B=400)
#look at the index.corrected column for optimism-corrected estimates
#logistic interept is 0 apparent but optimism-corrected is -0.0438
#logistic slope is 1 apparent but optimism-corrected is 0.9507 - indicating that high risks are over estimated and low risks are underestimated
#Assess Moderate Calibration
#Calibration curve
val.prob(predict(f,df,type="fitted"),df[,3], m=5, statloc=FALSE)
source("/Users/leahguthrie/Downloads/Module_7/SISCR2016_Module7_Rcode/val.prob.ci.June09.r")
val.prob.ci(predict(f,df,type="fitted"),df[,3], m=5)
set.seed(9876)
#DecisionCurve calculations for predicting cancer using age, sex, and smoking status
#set bootstraps = 50 here to reduce computation time.
baseline.model <- decision_curve(Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, #fitting a logistic model
data = df,
study.design = "cohort",
bootstraps = 50)
#plot the Decision curve for baseline model
#plot the Decision curve for baseline model
plot_decision_curve(baseline.model,  curve.names = "baseline model")
plot_decision_curve(baseline.model,  curve.names = "baseline model", xlim=c(0, .55))
plot_decision_curve(baseline.model, standardize=F, curve.names = "baseline model", xlim=c(0, 0.55))
baseline.model <- decision_curve(Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT, #fitting a logistic model
data = df,
study.design = "cohort",
bootstraps = 50)
#plot the Decision curve for baseline model
plot_decision_curve(baseline.model,  curve.names = "baseline model")
plot_decision_curve(baseline.model,  curve.names = "baseline model", xlim=c(0, .55))
plot_decision_curve(baseline.model, standardize=F, curve.names = "baseline model", xlim=c(0, 0.55))
#Examine the potential for the new biomarkers to improve Net Benefit
full.model <- decision_curve(Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df, bootstraps = 50)
#since we want to plot more than one curve, we pass a list of 'DecisionCurve' objects to the plot
plot_decision_curve( list(baseline.model, full.model),  curve.names = c("Baseline model", "Full model"), xlim=c(0, .55))
plot_decision_curve( list(baseline.model, full.model),  curve.names = c("Baseline model", "Full model"), xlim=c(0, .85))
plot_decision_curve( list(baseline.model, full.model),  curve.names = c("Baseline model", "Full model"), xlim=c(0, .55))
plot_decision_curve( list(baseline.model, full.model),  curve.names = c("Baseline model", "Full model"), xlim=c(0, 1))
summary(full.model)
modelfullsum <- summary(full.model)
#Plot ROC alternative for full model that includes biomarkers
plot_roc_components(full.model,  xlim = c(0, 0.4),col = c("black", "red"))
#Clinical Impact Plot for full model that includes biomarkers
plot_clinical_impact(full.model, xlim = c(0, .4), col = c("black", "blue"))
library(BioPET)
library(pROC)
library(ggplot2)
library(gridExtra)
enrichment.baseline.model<-enrichment_analysis(formula=Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT, data = df, cost.screening=50, cost.keeping=1000, reduction.under.treatment=0.7)
plot_enrichment_summaries(enrichment.baseline.model)
enrichment.full.model<-enrichment_analysis(formula=Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df, cost.screening=50, cost.keeping=1000, reduction.under.treatment=0.7)
enrichment.full.model<-enrichment_analysis(formula=Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df, cost.screening=50, cost.keeping=1000, reduction.under.treatment=0.7)
enrichment.full.model<-enrichment_analysis(formula=Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df, cost.screening=50, cost.keeping=1000, reduction.under.treatment=0.7)
plot_enrichment_summaries(enrichment.full.model)
f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData)
print(f)
?lrm
f<-lrm(Cancer~GGT + BMI +  Vegetables + Red.meat + Fiber + GOT + GPT+ Fruits, data = df)
print(f)
f<-lrm(Cancer~Age + Female + Smokes + Marker1 + Marker2, data = dcaData, x=TRUE, y=TRUE)
#set the seed for bootstrapping
set.seed(1796)
validate(f, B=400)
#look at the index.corrected column for optimism-corrected estimates
#logistic interept is 0 apparent but optimism-corrected is -0.0438
#logistic slope is 1 apparent but optimism-corrected is 0.9507 - indicating that high risks are over estimated and low risks are underestimated
val.prob(predict(f,dcaData,type="fitted"),dcaData[,6], m=50, statloc=FALSE)
source("/Users/leahguthrie/Downloads/Module_7/SISCR2016_Module7_Rcode/val.prob.ci.June09.r")
val.prob.ci(predict(f,dcaData,type="fitted"),dcaData[,6], m=50)
#to remove the statistics printed in the graph: set statloc=FALSE
##  INCREMENTAL VALUE
#Let's suppose that Marker 1 is and established biomarker and Marker 2 is a potentially useful new biomarker
set.seed(9876)
#DecisionCurve calculations for predicting cancer using age, sex, and smoking status
#set bootstraps = 50 here to reduce computation time.
baseline.model <- decision_curve(Cancer~Age + Female + Smokes + Marker1, #fitting a logistic model
data = dcaData,
study.design = "cohort",
bootstraps = 50)
#plot the Decision curve for baseline model
plot_decision_curve(baseline.model,  curve.names = "baseline model")
plot_decision_curve(baseline.model,  curve.names = "baseline model", xlim=c(0, .55))
#switch to Net Benefit rather than standardized Net Benefit
library(mmnet)
library(biom)
library("biomformat")
setwd("/Users/leahguthrie/Einstein/Kelly-Lab/Labnotebook/Projects/Infla_cazy/data/")
###read in file
mlow <- read.csv("KO_ctl_count.csv")
mlow <- read.csv("KO_ctl_count.csv")
mlow <- read.csv("KO_ctl_count.csv")
mlow <- read.csv("KO_ctl_count.csv")
###
KO <- mlow$State
abundance <- mlow$Ctl
abundance <- as.data.frame(abundance)
KO <- as.data.frame(KO)
biom.data <- make_biom(abundance, observation_metadata = KO)
biom.data$type <- "enzymatic genes abundance"
###Construct Low state specific network
ssn <- constructSSN(biom.data)
topologicalAnalyzeNet(ssn)
mlow <- read.csv("KO_aa_count.csv")
###
KO <- mlow$State
abundance <- mlow$AA
abundance <- as.data.frame(abundance)
KO <- as.data.frame(KO)
biom.data <- make_biom(abundance, observation_metadata = KO)
biom.data$type <- "enzymatic genes abundance"
###Construct Low state specific network
ssn <- constructSSN(biom.data)
topologicalAnalyzeNet(ssn)
mlow <- read.csv("KO_ca_count.csv")
head(mlow)
KO <- mlow$State
abundance <- mlow$CA
abundance <- as.data.frame(abundance)
KO <- as.data.frame(KO)
biom.data <- make_biom(abundance, observation_metadata = KO)
biom.data$type <- "enzymatic genes abundance"
###Construct Low state specific network
ssn <- constructSSN(biom.data)
topologicalAnalyzeNet(ssn)
mlow <- read.csv("ko_ibd_count.csv")
###
KO <- mlow$ID
abundance <- mlow$High_c
abundance <- as.data.frame(abundance)
KO <- as.data.frame(KO)
biom.data <- make_biom(abundance, observation_metadata = KO)
biom.data$type <- "enzymatic genes abundance"
###Construct Low state specific network
ssn <- constructSSN(biom.data)
topologicalAnalyzeNet(ssn)
mlow <- read.csv("ko_healthy_ibd_count")
mlow <- read.csv("ko_healthy_ibd_count.csv")
head(mlow)
KO <- mlow$ID
abundance <- mlow$Healthy_count
abundance <- as.data.frame(abundance)
KO <- as.data.frame(KO)
biom.data <- make_biom(abundance, observation_metadata = KO)
biom.data$type <- "enzymatic genes abundance"
###Construct Low state specific network
ssn <- constructSSN(biom.data)
topologicalAnalyzeNet(ssn)
install.packages("cluster")
install.packages("cluster")
install.packages("clusterSim")
library(cluster)
library(clusterSim)
setwd('/Users/leahguthrie/Einstein/Kelly-Lab/Labnotebook/Projects/Infla_cazy/data')
data=read.table("MetaHIT_SangerSamples.genus.txt", header=T, row.names=1, dec=".", sep="\t")
data=read.table("MetaHIT_41SangerSamples.genus.txt", header=T, row.names=1, dec=".", sep="\t")
head(data)
data=data[-1,]
head(data)
tail(data)
dist.JSD <- function(inMatrix, pseudocount=0.000001, ...) {
KLD <- function(x,y) sum(x *log(x/y))
JSD<- function(x,y) sqrt(0.5 * KLD(x, (x+y)/2) + 0.5 * KLD(y, (x+y)/2))
matrixColSize <- length(colnames(inMatrix))
matrixRowSize <- length(rownames(inMatrix))
colnames <- colnames(inMatrix)
resultsMatrix <- matrix(0, matrixColSize, matrixColSize)
inMatrix = apply(inMatrix,1:2,function(x) ifelse (x==0,pseudocount,x))
for(i in 1:matrixColSize) {
for(j in 1:matrixColSize) {
resultsMatrix[i,j]=JSD(as.vector(inMatrix[,i]),
as.vector(inMatrix[,j]))
}
}
colnames -> colnames(resultsMatrix) -> rownames(resultsMatrix)
as.dist(resultsMatrix)->resultsMatrix
attr(resultsMatrix, "method") <- "dist"
return(resultsMatrix)
}
data.dist=dist.JSD(data)
pam.clustering=function(x,k) { # x is a distance matrix and k the number of clusters
require(cluster)
cluster = as.vector(pam(as.dist(x), k, diss=TRUE)$clustering)
return(cluster)
}
data.cluster=pam.clustering(data.dist, k=3)
require(clusterSim)
nclusters = index.G1(t(data), data.cluster, d = data.dist, centrotypes = "medoids")
nclusters=NULL
for (k in 1:20) {
if (k==1) {
nclusters[k]=NA
} else {
data.cluster_temp=pam.clustering(data.dist, k)
nclusters[k]=index.G1(t(data),data.cluster_temp,  d = data.dist,
centrotypes = "medoids")
}
}
plot(nclusters, type="h", xlab="k clusters", ylab="CH index",main="Optimal number of clusters")
obs.silhouette=mean(silhouette(data.cluster, data.dist)[,3])
cat(obs.silhouette) #0.1899451
#data=noise.removal(data, percent=0.01)
## plot 1
obs.pca=dudi.pca(data.frame(t(data)), scannf=F, nf=10)
obs.pca=dudi.pca(data.frame(t(data)), scannf=F, nf=10)
?dudi.pca
obs.pca= dudi.pca(data.frame(t(data)), scannf=F, nf=10)
data(deug)
deug.dudi <- dudi.pca(deug$tab, center = deug$cent, scale = FALSE, scan = FALSE)
deug.dudi1 <- dudi.pca(deug$tab, center = TRUE, scale = TRUE, scan = FALSE)
data.dist=dist.JSD(data)
head(data.dist)
Head(data)
head(data)
data.dist
